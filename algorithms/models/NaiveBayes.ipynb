{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "TRAINING_SAMPLES = 142077\n",
    "TESTING_SAMPLES = 315726\n",
    "\n",
    "HASHING_VECTORIZER_FEATURES = 2**18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inversed Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tfidf(dataset_filename):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(dataset_filename, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        \n",
    "        for sentence in csv_reader:\n",
    "            sentences.append(sentence[1])\n",
    "            labels.append(0 if sentence[0] == '0' else 1)\n",
    "        \n",
    "        hashing_vectorizer = HashingVectorizer(n_features=HASHING_VECTORIZER_FEATURES, alternate_sign=False)\n",
    "        hashed_bow = hashing_vectorizer.transform(sentences)\n",
    "        \n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        tfidf = tfidf_transformer.fit_transform(hashed_bow)\n",
    "        \n",
    "        return tfidf, np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_classifier(input_data, labels_data):\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(input_data, labels_data)\n",
    "    joblib.dump(classifier, 'bayesClassifier.pkl')\n",
    "    \n",
    "\n",
    "def setup_pretrained_classifier(input_data, labels_data):\n",
    "    classifier = joblib.load('bayesClassifier.pkl')\n",
    "    classifier.partial_fit(input_data, labels_data, classes=[0, 1])\n",
    "    joblib.dump(classifier, 'bayesClassifier.pkl')\n",
    "\n",
    "\n",
    "def load_classifier():\n",
    "    return joblib.load('bayesClassifier.pkl')\n",
    "\n",
    "\n",
    "def train():\n",
    "    tfidf, labels = build_tfidf('mobile_1.csv')\n",
    "    \n",
    "    setup_classifier(tfidf, labels)\n",
    "    #setup_pretrained_classifier(tfidf, labels)\n",
    "\n",
    "\n",
    "# train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect predictions: 77849 (24.66%)\n",
      "Predicted sentiment: 59.47% positive, 40.53% negative\n",
      "Predicted sentiment: 41.00% positive, 59.00% negative\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement some evaluation measures (e.g. True/False Positives/Negatives and Precision, Recall, F1-score)\n",
    "\n",
    "def batch_inference(classifier):\n",
    "    tfidf, labels = build_tfidf('test.csv')\n",
    "    incorrect_predictions = []\n",
    "    \n",
    "    prediction_results = classifier.predict(tfidf)\n",
    "    for result_index, (predicted_result, ground_truth) in enumerate(zip(prediction_results, labels)):\n",
    "        if predicted_result != ground_truth:\n",
    "            incorrect_predictions.append(result_index)\n",
    "    \n",
    "    # TODO: Handle prediction results (e.g. compute evaluation measures, save them to a *.csv file for further fine-tuning).\n",
    "    print('Incorrect predictions: {} ({:.2f}%)'.format(len(incorrect_predictions), (len(incorrect_predictions) / TESTING_SAMPLES) * 100))\n",
    "\n",
    "\n",
    "def simple_inference(classifier, sentence):\n",
    "    hashing_vectorizer = HashingVectorizer(n_features=HASHING_VECTORIZER_FEATURES, alternate_sign=False)\n",
    "    hashed_bow = hashing_vectorizer.transform([sentence])\n",
    "        \n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidf = tfidf_transformer.fit_transform(hashed_bow)\n",
    "\n",
    "    prediction_result = classifier.predict_proba(tfidf)[0]\n",
    "    print('Predicted sentiment: {:.2f}% positive, {:.2f}% negative'.format(prediction_result[1] * 100, prediction_result[0] * 100))\n",
    "\n",
    "\n",
    "classifier = load_classifier()\n",
    "\n",
    "batch_inference(classifier)\n",
    "simple_inference(classifier, 'This classifier works quite well.')\n",
    "simple_inference(classifier, 'However the neural network performs better.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
